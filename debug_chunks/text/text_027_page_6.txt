How can we earn trust? To create positive impact with technology, people need to be able to trust the technologies they use and the companies behind them. For us, earning trust spans the responsible use of AI, protecting privacy, and advancing digital safety and cybersecurity. Our commitment to responsible AI is not new. Since 2017, we’ve worked to develop our responsible AI practice, recognizing that trust is never given but earned through action. We have translated our AI principles into a core set of implementation processes, as well as tools, training, and practices to support compliance. But internal programs aren’t enough. We also enable our customers and partners to develop and deploy AI safely, including through our AI customer commitments and services like Azure AI Studio, with its content safety tooling and access to our Responsible AI dashboard. Building AI responsibly requires that we work with other industry leaders, civil society, and governments to advocate for AI regulations and governance globally. This year, we released our Governing AI Blueprint, which outlines concrete legal and policy recommendations for AI guardrails. We are signatories to the eight voluntary commitments developed with the US White House, and proud of the six additional commitments we’ve made to further strengthen and operationalize the principles of safety, security, and trust. The era of AI heightens the importance of cybersecurity, and we deepened our work across the private and public sectors to improve cyber-resilience. We’ve continued to support Ukraine in defending critical infrastructure, detecting and disrupting cyberattacks and cyberinfluence operations, and providing intelligence related to these attacks. Our Microsoft Threat Analysis Center team produced more than 500 i